{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Varational Autoencoder for Genotype Imputation <span class=\"tocSkip\"></span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-data\" data-toc-modified-id=\"Loading-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Loading data</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Preprocessing</a></span></li></ul></li><li><span><a href=\"#Method\" data-toc-modified-id=\"Method-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-model\" data-toc-modified-id=\"Build-model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Build model</a></span></li><li><span><a href=\"#Generate-data\" data-toc-modified-id=\"Generate-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generate data</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#Save-model\" data-toc-modified-id=\"Save-model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Save model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is a case study of building a SCDA model by using completely convolutional layers with L1 regularization on the weigths, which achieves ~99% imputation accuracy on yeast genotype dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Lambda, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy,categorical_crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a seed for repeating the exact dataset splits\n",
    "np.random.seed(seed=28213)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3513, 28220)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name = '../data/yeast_genotype_train.txt'\n",
    "df_ori = pd.read_csv(input_name, sep='\\t', index_col=0)\n",
    "df_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33070_chrI_33070_A_T</th>\n",
       "      <th>33147_chrI_33147_G_T</th>\n",
       "      <th>33152_chrI_33152_T_C</th>\n",
       "      <th>33200_chrI_33200_C_T</th>\n",
       "      <th>33293_chrI_33293_A_T</th>\n",
       "      <th>33328_chrI_33328_C_A</th>\n",
       "      <th>33348_chrI_33348_G_C</th>\n",
       "      <th>33403_chrI_33403_C_T</th>\n",
       "      <th>33502_chrI_33502_A_G</th>\n",
       "      <th>33548_chrI_33548_A_C</th>\n",
       "      <th>...</th>\n",
       "      <th>12048853_chrXVI_925593_G_C</th>\n",
       "      <th>12049199_chrXVI_925939_T_C</th>\n",
       "      <th>12049441_chrXVI_926181_C_T</th>\n",
       "      <th>12050613_chrXVI_927353_T_G</th>\n",
       "      <th>12051167_chrXVI_927907_A_C</th>\n",
       "      <th>12051240_chrXVI_927980_A_G</th>\n",
       "      <th>12051367_chrXVI_928107_C_T</th>\n",
       "      <th>12052782_chrXVI_929522_C_T</th>\n",
       "      <th>12052988_chrXVI_929728_A_G</th>\n",
       "      <th>12053130_chrXVI_929870_C_T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_02</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_03</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_04</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_06</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       33070_chrI_33070_A_T  33147_chrI_33147_G_T  33152_chrI_33152_T_C  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     2                     2                     2   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     2                     2                     2   \n",
       "\n",
       "       33200_chrI_33200_C_T  33293_chrI_33293_A_T  33328_chrI_33328_C_A  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     2                     2                     2   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     2                     2                     2   \n",
       "\n",
       "       33348_chrI_33348_G_C  33403_chrI_33403_C_T  33502_chrI_33502_A_G  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     2                     2                     2   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     2                     2                     2   \n",
       "\n",
       "       33548_chrI_33548_A_C  ...  12048853_chrXVI_925593_G_C  \\\n",
       "SAMID                        ...                               \n",
       "01_01                     1  ...                           2   \n",
       "01_02                     1  ...                           2   \n",
       "01_03                     2  ...                           1   \n",
       "01_04                     1  ...                           1   \n",
       "01_06                     2  ...                           2   \n",
       "\n",
       "       12049199_chrXVI_925939_T_C  12049441_chrXVI_926181_C_T  \\\n",
       "SAMID                                                           \n",
       "01_01                           2                           2   \n",
       "01_02                           2                           2   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           2                           2   \n",
       "\n",
       "       12050613_chrXVI_927353_T_G  12051167_chrXVI_927907_A_C  \\\n",
       "SAMID                                                           \n",
       "01_01                           2                           2   \n",
       "01_02                           2                           2   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           2                           2   \n",
       "\n",
       "       12051240_chrXVI_927980_A_G  12051367_chrXVI_928107_C_T  \\\n",
       "SAMID                                                           \n",
       "01_01                           2                           2   \n",
       "01_02                           2                           2   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           2                           2   \n",
       "\n",
       "       12052782_chrXVI_929522_C_T  12052988_chrXVI_929728_A_G  \\\n",
       "SAMID                                                           \n",
       "01_01                           2                           2   \n",
       "01_02                           2                           2   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           2                           2   \n",
       "\n",
       "       12053130_chrXVI_929870_C_T  \n",
       "SAMID                              \n",
       "01_01                           2  \n",
       "01_02                           2  \n",
       "01_03                           1  \n",
       "01_04                           1  \n",
       "01_06                           2  \n",
       "\n",
       "[5 rows x 28220 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3513, 28220, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode\n",
    "df_onehot = to_categorical(df_ori)\n",
    "df_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2810, 28220, 3), (703, 28220, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split df to train and valid\n",
    "train_X, valid_X = train_test_split(df_onehot, test_size=0.2)\n",
    "\n",
    "train_X.shape, valid_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de entrenamiento\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Generador de datos para Denoising Autoencoder\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, batch_size, x_dataset, missing_perc=0.1, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.x = x_dataset\n",
    "        self.missing_perc = missing_perc\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(self.x.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        x_missing = self.x[indexes].copy()\n",
    "\n",
    "        for i in range(x_missing.shape[0]):\n",
    "            missing_size = int(self.missing_perc * x_missing.shape[1])\n",
    "            missing_index = np.random.randint(x_missing.shape[1], size=missing_size)\n",
    "            x_missing[i, missing_index, :] = [1, 0, 0]  # Ajusta según la estructura de los datos\n",
    "\n",
    "        return x_missing, self.x[indexes]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(self.x.shape[0])\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "# Instanciar el DataGenerator\n",
    "train_generator = DataGenerator(batch_size=batch_size, x_dataset=train_X, missing_perc=0.1)\n",
    "valid_generator = DataGenerator(batch_size=batch_size, x_dataset=valid_X, missing_perc=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer batch de entrenamiento:\n",
      " (array([[[1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]]]), array([[[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]]]))\n",
      "Primer batch de validación:\n",
      " (array([[[0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [1., 0., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.]],\n",
      "\n",
      "       [[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [0., 1., 0.]]]), array([[[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]],\n",
      "\n",
      "       [[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]]]))\n",
      "Valores únicos en el primer batch de entrenamiento: [0. 1.]\n",
      "Valores únicos en el primer batch de validación: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Obtener el primer batch para verificar\n",
    "first_batch_train = train_generator[0]\n",
    "first_batch_valid = valid_generator[0]\n",
    "\n",
    "print(\"Primer batch de entrenamiento:\\n\", first_batch_train)\n",
    "print(\"Primer batch de validación:\\n\", first_batch_valid)\n",
    "print(\"Valores únicos en el primer batch de entrenamiento:\", np.unique(first_batch_train))\n",
    "print(\"Valores únicos en el primer batch de validación:\", np.unique(first_batch_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Dimensiones\n",
    "#original_dim = train_X.shape[1]\n",
    "#latent_dim = 16  # Dimensión del espacio latente\n",
    "#intermediate_dim = 64\n",
    "#epsilon_std = 1.0\n",
    "original_dim = train_X.shape[1]\n",
    "latent_dim = 16\n",
    "intermediate_dim = 64\n",
    "kr = 1e-4  # L1 regularization factor\n",
    "drop_prec = 0.25\n",
    "inChannel = 3  # Number of channels in input (3 in this case)\n",
    "epsilon_std = 1.0\n",
    "kl_scale = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1806080</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">28,897,296</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">28,897,296</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84660</span>)     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,502,900</span> │ dense_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vae_loss_layer_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VAELossLayer</span>)      │                   │            │ reshape_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m64\u001b[0m) │        \u001b[38;5;34m256\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1806080\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │ \u001b[38;5;34m28,897,296\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │ \u001b[38;5;34m28,897,296\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,088\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84660\u001b[0m)     │  \u001b[38;5;34m5,502,900\u001b[0m │ dense_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vae_loss_layer_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mVAELossLayer\u001b[0m)      │                   │            │ reshape_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,298,836</span> (241.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,298,836\u001b[0m (241.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,298,836</span> (241.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,298,836\u001b[0m (241.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NO DA ERROR PERO PERDIDA NAN\n",
    "# Función de muestreo\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.random.normal(shape=(batch, dim), mean=0., stddev=epsilon_std)\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Modelo Encoder\n",
    "inputs = Input(shape=(original_dim, 3))\n",
    "h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "h = Flatten()(h)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Modelo Decoder\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim * 3, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "x_decoded_mean = Reshape((original_dim, 3))(x_decoded_mean)\n",
    "\n",
    "# Capa personalizada para calcular la pérdida VAE\n",
    "class VAELossLayer(Layer):\n",
    "    def call(self, inputs):\n",
    "        x, x_decoded_mean, z_mean, z_log_var = inputs\n",
    "        # Pérdida de entropía cruzada binaria\n",
    "        xent_loss = K.sum(categorical_crossentropy(x, x_decoded_mean), axis=1)  # Solo reducimos en la dimensión 1\n",
    "        # Pérdida KL\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=1)\n",
    "        # Suma de las pérdidas\n",
    "        return xent_loss + kl_loss\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],)\n",
    "\n",
    "# Aplicar la capa personalizada de pérdida\n",
    "loss_layer = VAELossLayer()([inputs, x_decoded_mean, z_mean, z_log_var])\n",
    "\n",
    "# Modelo final\n",
    "vae_final = Model(inputs, loss_layer)\n",
    "\n",
    "# Compilar el modelo (sin pérdida adicional, ya que la pérdida está en la capa)\n",
    "# Compilar el modelo con una pérdida dummy\n",
    "vae_final.compile(loss='categorical_crossentropy', \n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "vae_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7055</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7055</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7055</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">903040</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,448,656</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,448,656</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">903040</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15,351,680</span> │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7055</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7055</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ up_sampling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,272</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ up_sampling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ up_sampling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">483</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vae_loss_layer_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VAELossLayer</span>)      │                   │            │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m64\u001b[0m) │     \u001b[38;5;34m10,304\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7055\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7055\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7055\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m41,088\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m903040\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │ \u001b[38;5;34m14,448,656\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │ \u001b[38;5;34m14,448,656\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m903040\u001b[0m)    │ \u001b[38;5;34m15,351,680\u001b[0m │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7055\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7055\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m41,024\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ up_sampling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m64\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mUpSampling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m64\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ up_sampling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m32\u001b[0m) │     \u001b[38;5;34m10,272\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ up_sampling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mUpSampling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ up_sampling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │        \u001b[38;5;34m483\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ vae_loss_layer_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mVAELossLayer\u001b[0m)      │                   │            │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,352,675</span> (169.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,352,675\u001b[0m (169.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,352,675</span> (169.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,352,675\u001b[0m (169.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Dense, Lambda, Reshape, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "original_dim = train_X.shape[1]\n",
    "latent_dim = 16\n",
    "intermediate_dim = 64\n",
    "kr = 1e-4  # L1 regularization factor\n",
    "drop_prec = 0.25\n",
    "inChannel = 3  # Number of channels in input (3 in this case)\n",
    "epsilon_std = 1.0\n",
    "kl_scale = 0.001 \n",
    "\n",
    "\n",
    "# Función de muestreo\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim), mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Modelo Encoder\n",
    "inputs = Input(shape=(original_dim, inChannel))\n",
    "x = Conv1D(32, 5, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l1(kr))(inputs)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(drop_prec)(x)\n",
    "\n",
    "x = Conv1D(64, 5, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l1(kr))(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(drop_prec)(x)\n",
    "\n",
    "x = Conv1D(128, 5, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l1(kr))(x)\n",
    "\n",
    "# Flatten and latent space\n",
    "x = Flatten()(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Calcular la nueva forma después de Flatten para Reshape\n",
    "reshape_dim = original_dim // 4  # Recalcular reshape_dim para que se ajuste al tamaño final deseado\n",
    "\n",
    "# Decoder\n",
    "decoder_h = Dense(128 * reshape_dim, activation='relu')\n",
    "h_decoded = decoder_h(z)\n",
    "h_decoded = Reshape((reshape_dim, 128))(h_decoded)\n",
    "\n",
    "h_decoded = Conv1D(64, 5, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l1(kr))(h_decoded)\n",
    "h_decoded = UpSampling1D(size=2)(h_decoded)  # Ajustar el tamaño de upsampling\n",
    "h_decoded = Dropout(drop_prec)(h_decoded)\n",
    "\n",
    "h_decoded = Conv1D(32, 5, padding='same', activation='relu', kernel_regularizer=tf.keras.regularizers.l1(kr))(h_decoded)\n",
    "h_decoded = UpSampling1D(size=2)(h_decoded)  # Otro Upsampling para restaurar completamente la longitud\n",
    "h_decoded = Dropout(drop_prec)(h_decoded)\n",
    "\n",
    "# Ajustar longitud final si es necesario\n",
    "x_decoded_mean = Conv1D(inChannel, 5, padding='same', activation='sigmoid')(h_decoded)\n",
    "\n",
    "# Si la longitud no coincide, agregamos una capa adicional para ajustar\n",
    "if K.int_shape(x_decoded_mean)[1] != original_dim:\n",
    "    x_decoded_mean = Conv1D(inChannel, 1, activation='sigmoid')(x_decoded_mean)\n",
    "\n",
    "# Modelo VAE\n",
    "vae = Model(inputs, x_decoded_mean)\n",
    "\n",
    "# Pérdida VAE\n",
    "class VAELossLayer(Layer):\n",
    "    def call(self, inputs):\n",
    "        x, x_decoded_mean, z_mean, z_log_var = inputs\n",
    "        # Pérdida de entropía cruzada categórica\n",
    "        xent_loss = K.sum(categorical_crossentropy(x, x_decoded_mean), axis=1)\n",
    "        # Pérdida KL con escalado para evitar problemas numéricos\n",
    "        kl_loss = kl_scale * -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=1)\n",
    "        \n",
    "        # Comprobar si hay NaN en la pérdida y sustituir por cero\n",
    "        xent_loss = tf.where(tf.math.is_nan(xent_loss), tf.zeros_like(xent_loss), xent_loss)\n",
    "        kl_loss = tf.where(tf.math.is_nan(kl_loss), tf.zeros_like(kl_loss), kl_loss)\n",
    "\n",
    "        # Suma de las pérdidas\n",
    "        total_loss = xent_loss + kl_loss\n",
    "        return total_loss\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],)\n",
    "\n",
    "# Aplicar la capa personalizada de pérdida\n",
    "loss_layer = VAELossLayer()([inputs, x_decoded_mean, z_mean, z_log_var])\n",
    "\n",
    "# Modelo final\n",
    "vae = Model(inputs, loss_layer)\n",
    "\n",
    "# Compilar el modelo (sin pérdida adicional, ya que la pérdida está en la capa)\n",
    "vae.compile(optimizer='rmsprop', loss=lambda y_true, y_pred: y_pred)\n",
    "\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_vae_model_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"custom_vae_model_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14110</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7055</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7055</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7055</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">903040</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,448,656</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">14,448,656</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28220</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15,485,507</span> │ lambda_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_20 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m32\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_6[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_21 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14110\u001b[0m, \u001b[38;5;34m64\u001b[0m) │     \u001b[38;5;34m10,304\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7055\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ conv1d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7055\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_7[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7055\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m41,088\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m903040\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │ \u001b[38;5;34m14,448,656\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │ \u001b[38;5;34m14,448,656\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28220\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │ \u001b[38;5;34m15,485,507\u001b[0m │ lambda_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,434,723</span> (169.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,434,723\u001b[0m (169.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,434,723</span> (169.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,434,723\u001b[0m (169.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D, Dropout, Dense, Lambda, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "# Parámetros\n",
    "feature_size = train_X.shape[1]  # tamaño de la secuencia de entrada\n",
    "inChannel = 3       # canal de entrada\n",
    "kr = 0.001          # regularización L1\n",
    "drop_prec = 0.5     # tasa de dropout\n",
    "latent_dim = 16     # tamaño del espacio latente\n",
    "\n",
    "# Encoder\n",
    "inputs = Input(shape=(feature_size, inChannel))\n",
    "x = Conv1D(32, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))(inputs)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(drop_prec)(x)\n",
    "\n",
    "x = Conv1D(64, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(drop_prec)(x)\n",
    "\n",
    "x = Conv1D(128, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))(x)\n",
    "shape_before_flattening = K.int_shape(x)  # guardamos la forma antes del flattening\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Latent space: mean and log variance\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "# Sampling layer\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Decoder\n",
    "decoder_input = Input(K.int_shape(z)[1:])\n",
    "x = Dense(np.prod(shape_before_flattening[1:]))(decoder_input)\n",
    "x = Reshape(shape_before_flattening[1:])(x)\n",
    "\n",
    "x = Conv1D(128, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))(x)\n",
    "\n",
    "x = Conv1D(64, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))(x)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Dropout(drop_prec)(x)\n",
    "\n",
    "x = Conv1D(32, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))(x)\n",
    "x = UpSampling1D(2)(x)\n",
    "x = Dropout(drop_prec)(x)\n",
    "\n",
    "outputs = Conv1D(inChannel, 5, activation='sigmoid', padding='same')(x)  # Sigmoid para salida continua\n",
    "\n",
    "decoder = Model(decoder_input, outputs)\n",
    "z_decoded = decoder(z)\n",
    "\n",
    "# Loss function\n",
    "class CustomVAEModel(Model):\n",
    "    def vae_loss(self, inputs, z_decoded):\n",
    "        # Reconstruction loss\n",
    "        reconstruction_loss = binary_crossentropy(K.flatten(inputs), K.flatten(z_decoded))\n",
    "        reconstruction_loss *= feature_size * inChannel\n",
    "\n",
    "        # KL divergence\n",
    "        kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "\n",
    "        return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_decoded = decoder(z)\n",
    "        loss = self.vae_loss(inputs, z_decoded)\n",
    "        self.add_loss(loss)\n",
    "        return z_decoded\n",
    "\n",
    "vae = CustomVAEModel(inputs, z_decoded)\n",
    "\n",
    "# Compilar el modelo\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling CustomVAEModel.call().\n\n\u001b[1mTried to convert 'tensor' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n\u001b[0m\n\nArguments received by CustomVAEModel.call():\n  • inputs=tf.Tensor(shape=(None, 28220, 3), dtype=float64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entrenamiento del VAE usando el DataGenerator\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m vae_train \u001b[38;5;241m=\u001b[39m  \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/TFM/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[21], line 79\u001b[0m, in \u001b[0;36mCustomVAEModel.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     78\u001b[0m     z_decoded \u001b[38;5;241m=\u001b[39m decoder(z)\n\u001b[0;32m---> 79\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_decoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_loss(loss)\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z_decoded\n",
      "Cell \u001b[0;32mIn[21], line 67\u001b[0m, in \u001b[0;36mCustomVAEModel.vae_loss\u001b[0;34m(self, inputs, z_decoded)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvae_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, z_decoded):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Reconstruction loss\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     reconstruction_loss \u001b[38;5;241m=\u001b[39m binary_crossentropy(K\u001b[38;5;241m.\u001b[39mflatten(inputs), \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_decoded\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     68\u001b[0m     reconstruction_loss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m feature_size \u001b[38;5;241m*\u001b[39m inChannel\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# KL divergence\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling CustomVAEModel.call().\n\n\u001b[1mTried to convert 'tensor' to a tensor and failed. Error: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n\u001b[0m\n\nArguments received by CustomVAEModel.call():\n  • inputs=tf.Tensor(shape=(None, 28220, 3), dtype=float64)"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del VAE usando el DataGenerator\n",
    "\n",
    "vae_train =  vae.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=valid_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/6l7qymcs6md_xt6rzyf70x040000gn/T/ipykernel_41605/4018524515.py:6: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"b\" (-> color=(0.0, 0.0, 1.0, 1)). The keyword argument will take precedence.\n",
      "  plt.plot(range(len(loss)), loss, 'b', label='Training loss', color=\"black\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss curve on validation data\n",
    "loss = vae_train.history['loss']\n",
    "val_loss = vae_train.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(loss)), loss, 'b', label='Training loss', color=\"black\")\n",
    "plt.plot(range(len(val_loss)), val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# function modified -- key \"acc\" did not exist. the correct key is \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# plot accuracy curve on validation data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(vae_train\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m----> 4\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43mvae_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m#initially the key was acc\u001b[39;00m\n\u001b[1;32m      5\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m vae_train\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;66;03m#initially the key was val_ acc\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "# function modified -- key \"acc\" did not exist. the correct key is \n",
    "# plot accuracy curve on validation data\n",
    "print(vae_train.history.keys())\n",
    "acc = vae_train.history['accuracy'] #initially the key was acc\n",
    "val_acc = vae_train.history['val_accuracy']#initially the key was val_ acc\n",
    "plt.figure()\n",
    "plt.plot(range(len(acc)), acc, 'b', label='Training acc', color=\"black\")\n",
    "plt.plot(range(len(val_acc)), val_acc, 'b', label='Validation acc',color=\"blue\")\n",
    "plt.title('Training and validation acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDED: See numerical final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Loss: 0.017660541459918022\n",
      "Final Validation Loss: 0.014919193461537361\n",
      "Final Training Accuracy: 0.998394250869751\n",
      "Final Validation Accuracy: 0.9994722008705139\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Training Loss:\", loss[-1])\n",
    "print(\"Final Validation Loss:\", val_loss[-1])\n",
    "print(\"Final Training Accuracy:\", acc[-1])\n",
    "print(\"Final Validation Accuracy:\", val_acc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "vae.save('../models/VAE_yeast.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
